{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLEnv():\n",
    "    \n",
    "    \"\"\"\n",
    "    Using this class we will render an RL trading environment\n",
    "    \n",
    "    PortfolioValue: value of the finance portfolio\n",
    "    TransCost: Transaction cost that has to be paid by the agent to execute the action\n",
    "    ReturnRate: Percentage change in portfolio value\n",
    "    WindowSize: Number of trading periods to be considered\n",
    "    SplitSize: % of data to be used for training dataset, rest will be used for test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def initialize(self, Path, PortfolioValue = 10000, TransCost = 0.0025, ReturnRate = 0.02/250, \n",
    "                   WindowSize = 50, TrainTestSplit = 0.7):\n",
    "        # Here, we need to initialize values like portfolio values, transaction costs etc.\n",
    "        \n",
    "        # Loading dataset in Path to Dataset variable\n",
    "        self.Dataset = np.load(Path)\n",
    "        \n",
    "        # Number of stocks and associated values like Close, High, Low\n",
    "        self.NumStocks = self.Dataset.shape[1]\n",
    "        self.NumValues = self.Dataset.shape[0]\n",
    "        \n",
    "        # Initializing parameter\n",
    "        self.PortfolioValue = PortfolioValue\n",
    "        self.TransCost = TransCost\n",
    "        self.ReturnRate = ReturnRate\n",
    "        self.WindowSize = WindowSize\n",
    "        self.Done = False\n",
    "        \n",
    "        # Initiate state, action\n",
    "        self.state = None\n",
    "        self.TimeLength = None\n",
    "        self.Terminate = False\n",
    "        \n",
    "        # Termination cutoff\n",
    "        self.TerminateRows = int((self.Dataset.shape[2] - self.WindowSize) * TrainTestSplit)\n",
    "        \n",
    "    def UpdatedOpenValues(self, T):\n",
    "        # This function provides the \n",
    "        return np.array([1+self.ReturnRate]+self.Dataset[-1,:,T].tolist())\n",
    "    \n",
    "    def InputTensor(self, Tensor, T):\n",
    "        return Tensor[: , : , T - self.WindowSize:T]\n",
    "    \n",
    "    def ResetEnvironment(self, InitWeight, InitPortfolio, T):\n",
    "        self.state= (self.InputTensor(self.Dataset, self.WindowSize) , InitWeight , InitPortfolio)\n",
    "        self.TimeLength = self.WindowSize + T\n",
    "        self.Done = False\n",
    "        \n",
    "        return self.state, self.Done\n",
    "    \n",
    "    def Step(self, Action):\n",
    "        \"\"\"\n",
    "        Here, we get the action that needs to be performed at time step t, so, we get new weight vector,\n",
    "        reward function, updated value of portfolio\n",
    "        \n",
    "        We get the input tensor values for timestep t and for a given window size for each of the stocks \n",
    "        \n",
    "        State usually contains a input tensor, weight vector, portfolio vector\n",
    "        \"\"\"\n",
    "        \n",
    "        # Obtain input tensor\n",
    "        Dataset = self.InputTensor(self.Dataset, self.index)\n",
    "    \n",
    "    \n",
    "        # Current state values- current weight vector and portfolio vector\n",
    "        weight_vector_old = self.state[1]\n",
    "        portfolio_value_old = self.state[2]\n",
    "        \n",
    "        # Update the vector with opening values\n",
    "        NewOpenValues = self.UpdatedOpenValues(index)\n",
    "        \n",
    "        # Trading agent here provides new actions, that is new weight vector using which new \n",
    "        # allocations have to be done\n",
    "        WeightAllocation = Action\n",
    "        PortfolioAllocation = portfolio_value_old\n",
    "        \n",
    "        # While reallocating portfolios using weights we will have to account for transaction or \n",
    "        # commision rates\n",
    "        TransactionCost = PortfolioAllocation * self.TransCost * np.linalg.norm((WeightAllocation-weight_vector_old),ord = 1)\n",
    "        \n",
    "        # Inorder to find the new weight vector we need to obtain the value of present portfolio\n",
    "        # So as to obtain the value vector for each stock we need to multiply the portfolio value with the weight vector        \n",
    "        # Every time a stock portfolio is updated there is an additional transaction cost that incurs on the portfolio \n",
    "        # value\n",
    "        ValueAfterTransaction = (PortfolioAllocation * WeightAllocation) - np.array([cost]+ [0]*self.nb_stocks)\n",
    "        \n",
    "        # So the valueaftertransaction has cost deducted stock values for the previous day, when we multiply this vector\n",
    "        # with the latest open values\n",
    "        NewValueofStocks = ValueAfterTransaction * NewOpenValues\n",
    "        \n",
    "        # When we sum the stock prices of individual stock prices, we get the value of portfolio\n",
    "        NewPortfolioValue = np.sum(NewValueofStocks)\n",
    "        \n",
    "        # Inorder to obtain the new weight vector, we divide individual stock prices with total portfolio value\n",
    "        NewWeightVector = NewValueofStocks/NewPortfolioValue\n",
    "        \n",
    "        # After each timestep, value of the portfolio either decreases or increases depending on how the agent \n",
    "        # performs\n",
    "        RewardValue = (NewPortfolioValue - portfolio_value_old)/(portfolio_value_old)\n",
    "\n",
    "        self.index = self.index + 1\n",
    "        \n",
    "        # Using the computed values till now we can create new state\n",
    "        self.state = (self.InputTensor(self.Dataset, self.index), NewWeightVector, NewPortfolioValue)\n",
    "        \n",
    "        # Here, we have to compute termination criteria, when to terminate the step process\n",
    "        if index >= self.TerminateRows:\n",
    "            self.Done = True\n",
    "            \n",
    "        return self.state, self.RewardValue, self.Done  \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
